{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7640c6e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.embeddings.groq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GroqEmbeddings\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      5\u001b[0m load_dotenv()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain.embeddings.groq'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.embeddings.groq import GroqEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load your Groq API key from .env\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize Groq Embeddings\n",
    "embeddings_model = GroqEmbeddings(api_key=api_key)\n",
    "\n",
    "# Example short sentence\n",
    "sentence = \"Tata Consultancy Services is a leading IT company in India.\"\n",
    "\n",
    "# Generate embeddings\n",
    "vector = embeddings_model.embed_query(sentence)\n",
    "\n",
    "print(\"Embedding vector length:\", len(vector))\n",
    "print(\"First 10 dimensions:\", vector[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9409ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_18544\\4077586286.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "texts = [\"Infosys is a multinational IT company.\"]\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61117ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2d2b1fa5540>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10bc4046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector length: 384\n",
      "First 10 dimensions: [-0.030184494331479073, -0.02259017527103424, 0.00886974111199379, -0.05324116349220276, 0.05300078168511391, -0.14952747523784637, 0.07439170777797699, 0.006610870361328125, -0.009535393677651882, -0.03792954608798027]\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize the embedding model\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Example text\n",
    "text = \"Infosys is a multinational IT company.\"\n",
    "\n",
    "# Generate embedding\n",
    "vector = embeddings_model.embed_query(text)\n",
    "\n",
    "# Print embedding\n",
    "print(\"Embedding vector length:\", len(vector))\n",
    "print(\"First 10 dimensions:\", vector[:10])  # print first 10 numbers for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae23085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded!\n",
      "ChatGroq Symbol Bot ready! Type 'exit' to quit.\n",
      "[DEBUG] Model chose NOT to call the tool.\n",
      "Bot: Hello. How can I assist you today?\n",
      "[DEBUG] Model chose NOT to call the tool.\n",
      "Bot: The symbol of the Nifty index is ^NSEI or NIFTY. However, it's often represented by its benchmark index symbol, which is NSE:NIFTY or .NSEI.\n",
      "[DEBUG] Model chose to call tool with query: 'nifty index symbol'\n",
      "[DEBUG] Tool returned top 2 results:\n",
      "Company: NIFTYHOUSING-INDEX, Symbol: NSE:NIFTYHOUSING-INDEX\n",
      "Company: NIFTYINFRA-INDEX, Symbol: NSE:NIFTYINFRA-INDEX\n",
      "Bot: The Fyers symbol for Nifty is \"NIFTY\".\n",
      "[DEBUG] Model chose to call tool with query: 'nifty 50 company symbols'\n",
      "[DEBUG] Tool returned top 2 results:\n",
      "Company: NIFTY ALPHA 50-INDEX, Symbol: NSE:NIFTYALPHA50-INDEX\n",
      "Company: NIFTY50SHARIAH-INDEX, Symbol: NSE:NIFTY50SHARIAH-INDEX\n",
      "Bot: The Nifty 50 is a stock market index composed of 50 of the largest and most liquid Indian companies. It is one of the main stock indices used to measure the performance of the Indian stock market. \n",
      "\n",
      "Some of the top constituents of the Nifty 50 index include:\n",
      "\n",
      "1. Reliance Industries (RELIANCE)\n",
      "2. HDFC Bank (HDFCBANK)\n",
      "3. ICICI Bank (ICICIBANK)\n",
      "4. Infosys (INFY)\n",
      "5. ITC (ITC)\n",
      "6. Larsen & Toubro (LT)\n",
      "7. Axis Bank (AXISBANK)\n",
      "8. Bharti Airtel (BHARTIARTL)\n",
      "9. State Bank of India (SBIN)\n",
      "10. Tata Consultancy Services (TCS)\n",
      "\n",
      "Please note that the constituents of the Nifty 50 index can change over time due to periodic reviews by the index provider.\n",
      "\n",
      "The symbol for the Nifty 50 index itself is NSE:NIFTY.\n",
      "[DEBUG] Model chose NOT to call the tool.\n",
      "Bot: The symbol of the Nifty Fifty index is NIFTY.\n",
      "[DEBUG] Model chose to call tool with query: 'nifty 50 index symbol fyers'\n",
      "[DEBUG] Tool returned top 2 results:\n",
      "Company: NIFTY50VALUE 20-INDEX, Symbol: NSE:NIFTY50VALUE20-INDEX\n",
      "Company: NIFTY50-INDEX, Symbol: NSE:NIFTY50-INDEX\n",
      "Bot: The symbol for the Nifty 50 index on Fyers is NIFTY50. However, it's also commonly represented as NSE:NIFTY50 or INDEX:NIFTY50 in some trading platforms, but the base symbol is NIFTY50.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# -----------------------------\n",
    "# Load environment variables\n",
    "# -----------------------------\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# -----------------------------\n",
    "# Load saved vector store\n",
    "# -----------------------------\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", embeddings_model, allow_dangerous_deserialization=True)\n",
    "print(\"Vector store loaded!\")\n",
    "\n",
    "# -----------------------------\n",
    "# Initialize ChatGroq LLM\n",
    "# -----------------------------\n",
    "llm = ChatGroq(\n",
    "    api_key=api_key,\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Define LangChain ChatPromptTemplate\n",
    "# -----------------------------\n",
    "system_template = \"\"\"You are a helpful assistant. \n",
    "You can optionally call a tool to retrieve company stock symbols if needed.\n",
    "Use the tool results only if relevant, otherwise answer normally.\"\"\"\n",
    "system_msg_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"\"\"User Question:\n",
    "{user_query}\n",
    "\n",
    "Tool Output (use only if relevant):\n",
    "{retrieved_info}\n",
    "\n",
    "Answer:\"\"\"\n",
    "human_msg_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_msg_prompt, human_msg_prompt])\n",
    "\n",
    "# -----------------------------\n",
    "# Define the \"tool\"\n",
    "# -----------------------------\n",
    "def symbol_lookup_tool(query_str, top_k=2):\n",
    "    \"\"\"\n",
    "    Returns top_k most similar company entries from the vector store.\n",
    "    \"\"\"\n",
    "    docs = vectorstore.similarity_search(query_str, k=top_k)\n",
    "    results = [doc.page_content for doc in docs]\n",
    "    return results\n",
    "\n",
    "# -----------------------------\n",
    "# Chat loop\n",
    "# -----------------------------\n",
    "print(\"ChatGroq Symbol Bot ready! Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"You: \")\n",
    "    if user_query.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    # Step 1: Ask the model whether to use the tool and what string to query\n",
    "    tool_decision_prompt = f\"\"\"\n",
    "You are a chatbot. The user asked: \"{user_query}\".\n",
    "Decide if you need to call the 'symbol_lookup_tool' to find company symbols.\n",
    "If yes, generate a short string to query the tool (do not just repeat the user input).\n",
    "If no, just respond 'NO_TOOL'.\n",
    "Return only one line: either 'NO_TOOL' or the query string to pass to the tool.\n",
    "\"\"\"\n",
    "    decision_response = llm.invoke([\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", tool_decision_prompt)\n",
    "    ])\n",
    "    tool_query = decision_response.content.strip()\n",
    "    \n",
    "    # Step 2: Call the tool if needed\n",
    "    if tool_query != \"NO_TOOL\":\n",
    "        tool_results = symbol_lookup_tool(tool_query, top_k=2)\n",
    "        retrieved_info = \"\\n\".join(tool_results)\n",
    "        print(f\"[DEBUG] Model chose to call tool with query: '{tool_query}'\")\n",
    "        print(f\"[DEBUG] Tool returned top 2 results:\\n{retrieved_info}\")\n",
    "    else:\n",
    "        retrieved_info = \"No tool call needed.\"\n",
    "        print(f\"[DEBUG] Model chose NOT to call the tool.\")\n",
    "\n",
    "    # Step 3: Format messages using ChatPromptTemplate\n",
    "    messages = chat_prompt.format_messages(user_query=user_query, retrieved_info=retrieved_info)\n",
    "\n",
    "    # Step 4: Get final response from model\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    print(\"Bot:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58fdeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
